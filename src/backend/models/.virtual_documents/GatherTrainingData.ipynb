import talib
import pandas as pd
import yfinance as yf
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split






ticker = yf.download("INTC","2010-01-01", "2024-12-30")


ticker.columns = [col[0] for col in ticker.columns]
ticker.index = pd.to_datetime(ticker.index)
ticker.head()
ticker.describe()



# Price Trend Indicators
ticker['SMA_20'] = talib.SMA(ticker['Close'], timeperiod=20)
ticker['EMA_20'] = talib.EMA(ticker['Close'], timeperiod=20)

# MACD
ticker['MACD'], ticker['MACD_Signal'], ticker['MACD_Hist'] = talib.MACD(ticker['Close'])

# Bollinger Bands
ticker['BB_Upper'], ticker['BB_Middle'], ticker['BB_Lower'] = talib.BBANDS(ticker['Close'])

# Parabolic SAR
ticker['SAR'] = talib.SAR(ticker['High'], ticker['Low'])

# Momentum Indicators
ticker['RSI'] = talib.RSI(ticker['Close'])
ticker['STOCH_K'], ticker['STOCH_D'] = talib.STOCH(ticker['High'], ticker['Low'], ticker['Close'])
ticker['WILLR'] = talib.WILLR(ticker['High'], ticker['Low'], ticker['Close'])
ticker['ROC'] = talib.ROC(ticker['Close'])

# Volume Indicators
ticker['OBV'] = talib.OBV(ticker['Close'], ticker['Volume'])
ticker['AD'] = talib.AD(ticker['High'], ticker['Low'], ticker['Close'], ticker['Volume'])
ticker['MFI'] = talib.MFI(ticker['High'], ticker['Low'], ticker['Close'], ticker['Volume'])

# Volatility Indicators
ticker['ATR'] = talib.ATR(ticker['High'], ticker['Low'], ticker['Close'])
ticker['STDDEV'] = talib.STDDEV(ticker['Close'])

# Trend Strength Indicators
ticker['ADX'] = talib.ADX(ticker['High'], ticker['Low'], ticker['Close'])
ticker['PLUS_DI'] = talib.PLUS_DI(ticker['High'], ticker['Low'], ticker['Close'])
ticker['MINUS_DI'] = talib.MINUS_DI(ticker['High'], ticker['Low'], ticker['Close'])

# Ichimoku Cloud
ticker['ICHIMOKU_CONV'] = talib.HT_TRENDLINE(ticker['Close'])

# For Fibonacci and Pivot Points, you'll need custom calculations:
def calculate_pivot_points(df):
    pivot = (df['High'] + df['Low'] + df['Close']) / 3
    r1 = 2 * pivot - df['Low']
    s1 = 2 * pivot - df['High']
    return pivot, r1, s1

ticker['PIVOT'], ticker['R1'], ticker['S1'] = calculate_pivot_points(ticker)


ticker.tail()





ticker.to_csv("INTC_Stock.csv")






# Load and prepare data
df = pd.read_csv("INTC_Stock.csv", index_col='Date', parse_dates=True)
df['Target'] = df['Close'].shift(-1) / df['Close'] - 1
df = df.dropna()

X = df.drop(['Target', 'Close', 'High', 'Low', 'Open'], axis=1)
y = df['Target']

# Split and scale
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Adjust feature selection parameters
def correlation_selection(X, y, threshold=0.01):  # Lowered from 0.1
    correlations = pd.Series(abs(np.corrcoef(X, y, rowvar=False)[:-1, -1]), 
                           index=X.columns)
    selected = correlations[correlations > threshold].sort_values(ascending=False)
    print("\nFeature correlations with target:")
    print(selected)
    return selected.index.tolist()

def rf_importance_selection(X, y, threshold=0.005):  # Lowered from 0.01
    rf = RandomForestRegressor(n_estimators=100, random_state=42)
    rf.fit(X, y)
    importances = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)
    print("\nRandom Forest feature importances:")
    print(importances)
    return importances[importances > threshold].index.tolist()

def mutual_info_selection(X, y, k=15):  # Increased from 10
    selector = SelectKBest(score_func=mutual_info_regression, k=k)
    selector.fit(X, y)
    scores = pd.Series(selector.scores_, index=X.columns).sort_values(ascending=False)
    print("\nMutual Information scores:")
    print(scores)
    return X.columns[selector.get_support()].tolist()

# Apply updated selection methods
X_train_df = pd.DataFrame(X_train_scaled, columns=X.columns)
corr_features = correlation_selection(X_train_df, y_train)
mi_features = mutual_info_selection(X_train_df, y_train)
rf_features = rf_importance_selection(X_train_df, y_train)

# Find common features
common_features = list(set(corr_features) & set(mi_features) & set(rf_features))
print("\nCommon features:", common_features)
print("Correlation-based features:", corr_features)
print("\nMutual Information features:", mi_features)
print("\nRandom Forest important features:", rf_features)
print("\nCommon features:", list(set(corr_features) & set(mi_features) & set(rf_features)))
